global_config:
  image:
    target_size: [1024, 1024]
    supported_dims:
      - [1024, 1024]
      - [1152, 896]
      - [896, 1152]
      - [1216, 832]
      - [832, 1216]
      - [1344, 768]
      - [768, 1344]
      - [1536, 640]
      - [640, 1536]
    max_size: [1536, 1536]
    min_size: [640, 640]
    max_dim: 2359296  # 1536 * 1536
    max_aspect_ratio: 2.0  # Maximum allowed aspect ratio for images
  cache:
    cache_dir: "cache"
    use_cache: true
    clear_cache_on_start: false
  seed: null
  output_dir: "outputs"

model:
  pretrained_model_name: "stabilityai/stable-diffusion-xl-base-1.0"
  num_timesteps: 1000
  sigma_min: 0.002
  sigma_max: 2000.0
  rho: 7.0

training:
  batch_size: 4
  gradient_accumulation_steps: 1
  mixed_precision: true
  gradient_checkpointing: true
  memory:
    enable_24gb_optimizations: true
    layer_offload_fraction: 0.5 # Fraction of layers to offload to CPU best % is 0.5
    enable_activation_offloading: true
    enable_async_offloading: true
    temp_device: "cpu"
  optimizer:
    type: "adamw"  # Options: adamw, adamw_bf16, adamw_kahan, soap
    soap_config:
      precondition_frequency: 10
      max_precond_dim: 10000
      merge_dims: false
      precondition_1d: false
      normalize_grads: false
    kahan_config:
      warmup_steps: 500
      kahan_sum: true
  learning_rate: 4.0e-7
  max_grad_norm: 1.0
  num_epochs: 100
  warmup_steps: 500
  save_steps: 500
  log_steps: 10
  eval_steps: 100
  validation_steps: 1000
  max_train_steps: null
  lr_scheduler: "linear"
  optimizer_betas: [0.9, 0.999]
  weight_decay: 1.0e-2
  optimizer_eps: 1.0e-8
  method: "ddpm"  # Available: ddpm, flow_matching, consistency, dpm
  ddpm:
    # Prediction types:
    # - v_prediction: Velocity prediction (NovelAI style), faster convergence
    # - epsilon: Classic noise prediction, more stable
    # - sample: Direct sample prediction (experimental)
    prediction_type: "v_prediction"
    snr_gamma: 5.0
    zero_terminal_snr: true
    sigma_min: 0.002
    sigma_max: 2000.0
    rho: 7.0

data:
  # Supports both Windows and Unix paths
  # Windows paths (D:\Dataset) will be automatically converted to WSL paths (/mnt/d/Dataset)
  train_data_dir: 
    - "D:\\Datasets\\High-quality-photo10k"  # Windows path
  num_workers: 4
  pin_memory: true
  persistent_workers: true
  proportion_empty_prompts: 0.05

tag_weighting:
  enable_tag_weighting: true
  use_cache: true
  default_weight: 1.0
  min_weight: 0.1
  max_weight: 10.0
  smoothing_factor: 0.1
